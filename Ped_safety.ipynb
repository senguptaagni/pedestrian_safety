{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classification of pedestrian and bicycle crashes and near-miss events\n",
        "Pedestrian and bicycle crashes (and near-miss) events at intersection are identified by an AI-based model trained using video collected from traffic camera. This study evaluates the effectiveness or reliability of different automatically generated surrogates for crash modeling.\n",
        "\n",
        "The models considered in this study:\n",
        "*   Logistic regression\n",
        "*   Decision tree\n",
        "*   Random forest\n",
        "*   XGBoost\n"
      ],
      "metadata": {
        "id": "xwpI8WLsMshA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "2sCfSqGJ_7vK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# install packages and functions\n",
        "%%capture\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# Visualization packages\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn\n",
        "!pip install scikit-plot\n",
        "import scikitplot as skplt\n",
        "!pip install dtreeviz\n",
        "!apt-get install graphviz\n",
        "!pip install shap\n",
        "import shap\n",
        "plt.style.use('ggplot')\n",
        "\n",
        "# Data preprocessing and performance metric\n",
        "from sklearn.preprocessing import StandardScaler, OrdinalEncoder, OneHotEncoder\n",
        "from sklearn.model_selection import train_test_split,cross_val_score,StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix,classification_report,\\\n",
        "                            precision_score, recall_score, f1_score, accuracy_score\n",
        "from sklearn.compose import make_column_transformer\n",
        "\n",
        "# Machine learning packages\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "!pip install -q xgboost==1.5.0\n",
        "import xgboost\n",
        "\n",
        "# Generalized linear model - Logistic regression\n",
        "import statsmodels.api as sm\n",
        "import statsmodels.formula.api as smf\n",
        "\n",
        "# Oversampling\n",
        "from imblearn.over_sampling import SMOTENC\n",
        "from collections import Counter\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore', category=UserWarning)\n",
        "\n",
        "#Hyperparameter tuning\n",
        "!pip install -q bayesian-optimization\n",
        "from bayes_opt import BayesianOptimization\n",
        "\n",
        "seed = 42 #for reproducibility"
      ],
      "metadata": {
        "id": "Nz0I-9trMpcj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data description\n",
        "We use the data from Pennsylvania Department of Transportation (PennDOT). The data consists of variables related to pedestrian and bicycle crashes collected using an automated detection system. Although, the datasheet contains additional variables (Evasive action, VRU awareness) that are not collected by the automated system, we do not use them for modeling purposes."
      ],
      "metadata": {
        "id": "79akJiyoA0u3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EpqyaX7Waf6I"
      },
      "outputs": [],
      "source": [
        "#upload the data from drive (Note: if loaded in the files, do not need to run this again)\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset\n",
        "dataframe = pd.read_excel('PedBike_safety.xlsx',sheet_name='data grouped')\n",
        "dataframe.rename(columns = lambda x: x.replace(' ', '_'), inplace=True)\n",
        "\n",
        "crash_data = dataframe[['PET', 'Arrived_First', 'R1_Movement', 'R1_Type','R1_Conflict_Speed', 'R1_Median_Speed', \n",
        "                        'R2_Movement','R2_Type', 'R2_Conflict_Speed', 'R2_Median_Speed','VRU_Type', \n",
        "                        'FarsideNearside_VRU', 'VRU_Location', 'Vehicle_Signal', \n",
        "                        'VRU_Signal', 'Proximity', 'Confirmed_Conflict', 'Lighting', 'Weather']]\n"
      ],
      "metadata": {
        "id": "rzmMGQ4Wa9Jh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# crash_data = crash_data.loc[crash_data['VRU_Type'] == \"Pedestrian\"]"
      ],
      "metadata": {
        "id": "FeE6S4G8QxMP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "DataFrame contains data from various locations in PA. We would be using data from all locations, however, to ignore a specific location, use the following command after loading the data:\n",
        "```\n",
        "dataframe[dataframe['Location'].str.contains(\"Atherton Blue course near-miss\") == False]\n",
        "```\n",
        "Next, response variable ```Confirmed_Conflict``` is mapped to binary values of 1 and 0 for positive and negative classes respectively. Before performing the exploratory analysis and running models, check if ```NULL/NA``` values in all columns are zero by running the following command:\n",
        "```\n",
        "crash_data.isnull().sum()\n",
        "```"
      ],
      "metadata": {
        "id": "n1Sf9nJLeOl6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.options.mode.chained_assignment = None\n",
        "\n",
        "confirmed_conflict = {'Yes': 1, 'No': 0}\n",
        "crash_data['Confirmed_Conflict'] = crash_data['Confirmed_Conflict'].map(confirmed_conflict)\n",
        "\n",
        "crash_data = crash_data.dropna()"
      ],
      "metadata": {
        "id": "KkfLU4iWn98W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Summary statistics"
      ],
      "metadata": {
        "id": "0olZm2P6l9Ni"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(figsize=(4, 3))\n",
        "fig = seaborn.kdeplot(x ='R1_Median_Speed', data = crash_data, palette ='mako', \n",
        "                      shade=True, label='R1_Conflict_Speed', ax=ax).set(xlim=(0, max(crash_data['R1_Conflict_Speed'].max(),crash_data['R1_Median_Speed'].max()))) \n",
        "fig = seaborn.kdeplot(x ='R2_Median_Speed', data = crash_data, palette ='mako', shade=True, label='R2_Median_Speed', ax=ax)\n",
        "ax.legend()\n",
        "plt.xlabel('Speed')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ZNaecCh-4tcI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, ax = plt.subplots(figsize=(6, 4))\n",
        "seaborn.countplot(x ='Arrived_First', data = crash_data, palette ='mako') # to add title include this> .set(title='Title of Plot') \n",
        "plt.show()"
      ],
      "metadata": {
        "id": "tsRzDjJGuj6m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(figsize=(4, 3))\n",
        "fig = seaborn.kdeplot(x ='PET', data = crash_data, palette ='mako', shade=True, label='PET', ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "v04zqoCl7FXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.style.use('default')\n",
        "fig, ax = plt.subplots(figsize=(4, 3))\n",
        "fig = seaborn.boxplot(x ='PET', y = 'R1_Type', data = crash_data, palette ='mako', notch = True, ax=ax)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "U1qiD7TY74I3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Methodology\n",
        "The dataset is randomly split into two identically distributed datasets ```train``` and ```test``` for training the models and evaluating performances respectively. Notice, the class-imbalance in the dataset, which often limits the model performances. Here, we would consider training models with the true (i.e. imbalanced) data and balanced data by artificially adding synthetic samples corresponding to minority class."
      ],
      "metadata": {
        "id": "xCVld1aBmifY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train, test = train_test_split(crash_data, test_size=0.3, random_state=seed) # 70% training and 30% test\n",
        "\n",
        "counter = Counter(train['Confirmed_Conflict'])\n",
        "print(counter)"
      ],
      "metadata": {
        "id": "EWingP28qpal"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We use Synthetic Minority Oversampling Technique-NC (SMOTE-NC) - a variant of SMOTE algorithm that works on numerical and categotical datasets, to balance our dataset. SMOTE works by creating synthetic samples for the minority class by interpolating the feature space distribution of the minority class. Note, the oversampling is performed on the ```train``` dataset only. If you want to run, the analysis without the oversampling, then proceed to next section."
      ],
      "metadata": {
        "id": "mY7DlSC64P1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#define variable types\n",
        "cat_data = ['Arrived_First', 'R1_Movement','R1_Type','R2_Movement','R2_Type', 'VRU_Type', 'FarsideNearside_VRU',\n",
        "            'VRU_Location', 'Vehicle_Signal', 'VRU_Signal', 'Proximity', 'Lighting', 'Weather']\n",
        "\n",
        "numeric_data = ['PET', 'R1_Conflict_Speed', 'R1_Median_Speed', 'R2_Conflict_Speed', 'R2_Median_Speed']"
      ],
      "metadata": {
        "id": "AGHkOKvriET5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "smote = SMOTENC(random_state=seed, categorical_features= [train.drop(['Confirmed_Conflict'],axis=1).columns.get_loc(col) for col in cat_data])\n",
        "X_sm, y_sm = smote.fit_resample(train.drop(['Confirmed_Conflict'],axis=1), train['Confirmed_Conflict'])\n",
        "\n",
        "train = pd.concat([X_sm, y_sm], axis=1) #balanced "
      ],
      "metadata": {
        "id": "nL9fyxFbkFhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logistic Regression\n",
        "We will fit a Logistic regression model using the Generalized Linear Model ```glm()``` with argument ```family=sm.families.Binomial```. \n",
        "We use ```formula``` to define predictor and response variables in the model. Re-run the model by dropping one or many insignifcant variables from the variables list."
      ],
      "metadata": {
        "id": "NfY6_8f-VRxv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "logit_train = train.drop(train[train['Arrived_First']==\"Motorcycle\"].index) #we might need to drop specific categories based on p-value\n",
        "logit_test = test.drop(test[test['Arrived_First']==\"Motorcycle\"].index) \n",
        "\n",
        "formula = 'Confirmed_Conflict ~ PET + Arrived_First + R1_Movement + R1_Conflict_Speed +\\\n",
        "          R2_Conflict_Speed + Vehicle_Signal + VRU_Signal + Proximity + Weather' # re-run model with differernt variable combination\n",
        "\n",
        "formula_ped = 'Confirmed_Conflict ~ PET + R1_Movement + R1_Conflict_Speed +  R1_Median_Speed+ R2_Median_Speed +\\\n",
        "          R2_Conflict_Speed + Vehicle_Signal + VRU_Signal + Proximity + Weather + FarsideNearside_VRU' # re-run model with differernt variable combination          \n",
        "\n",
        "logitmodel = smf.glm(formula_ped, logit_train, family=sm.families.Binomial())\n",
        "\n",
        "model_logit = logitmodel.fit()\n",
        "print(model_logit.summary())"
      ],
      "metadata": {
        "id": "NTmrwQKGVJHR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Once the model is trained, we predict class probabilities ```y_logit_proba``` on the ```test``` split of the data with arguments ```transform=True``` and ```linear=False```. Note, the class probabilities need to be converted to corresponding class labels using a suitable threshold. Typically, a threshold of 0.5 is chosen for binary classifications, but should ideally chosen a threshold that maximizes a specific evaluation metric - for example, F1-score, as we consider here."
      ],
      "metadata": {
        "id": "UrKvaiX4XejV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "y_logit_proba = model_logit.predict(logit_test, transform=True, linear=False) #prob being in Class 1\n",
        "\n",
        "f1 = []\n",
        "values = np.linspace(0, 1, num=21)\n",
        "for cutoff in values:\n",
        "  predictions_nominal = [0 if x < cutoff  else 1 for x in y_logit_proba]\n",
        "  f1.append(f1_score(logit_test['Confirmed_Conflict'], predictions_nominal, average=\"macro\"))\n",
        "\n",
        "f1_logit = f1[np.argmax(f1)]\n",
        "thres_logit = values[np.argmax(f1)]\n",
        "print(\"Optimum macro F1 score = {:0.2f}; Threshold = {:0.2f}\".format(f1_logit, thres_logit))"
      ],
      "metadata": {
        "id": "7eOL7Eh7qcDc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Classification results for threshold of 0.5 can be evalauted by using ```thres_logit=0.5``` before running the next code chunk."
      ],
      "metadata": {
        "id": "pjqTe7lWyrLb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_logit = [0 if x < thres_logit else 1 for x in y_logit_proba]\n",
        "print(classification_report(logit_test['Confirmed_Conflict'], ypred_logit))"
      ],
      "metadata": {
        "id": "S_-tDmA8ysCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score versus threshold\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(values, f1)\n",
        "plt.plot(thres_logit,f1_logit,marker=\"o\", markersize=5)\n",
        "plt.xlabel('Probability threshold')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('Optimum F1 score - Logit')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "RKg-avWXaqdj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_prob = np.stack(((1-y_logit_proba).values, y_logit_proba.values), axis=1) # create a 2 dimensional array with probabilities of 0 and 1\n",
        "\n",
        "\n",
        "skplt.metrics.plot_roc(logit_test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "skplt.metrics.plot_precision_recall(logit_test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "dpn4f3vwJJLg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "cross-validation score check"
      ],
      "metadata": {
        "id": "gRpyx8GIn5-T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "class statsmodel(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, sm_class, formula):\n",
        "        self.sm_class = sm_class\n",
        "        self.formula = formula\n",
        "        self.model = None\n",
        "        self.result = None\n",
        " \n",
        "    def fit(self,data,dummy):\n",
        "        self.model = self.sm_class(self.formula,data)\n",
        "        self.result = self.model.fit()\n",
        " \n",
        "    def predict(self,X):\n",
        "        temp = self.result.predict(X)\n",
        "        temp = [ 0 if x < thres_logit else 1 for x in temp]\n",
        "        return temp"
      ],
      "metadata": {
        "id": "6HVUxcd2MuwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a model\n",
        "logitmodel_CV = statsmodel(smf.glm, formula)\n",
        "cv = StratifiedKFold(n_splits=3, random_state=seed, shuffle=True)\n",
        "\n",
        "# Print cross val score on this model\n",
        "print (cross_val_score(logitmodel_CV, logit_train, logit_train['Confirmed_Conflict'], cv=cv, scoring='f1_macro'))"
      ],
      "metadata": {
        "id": "P7cgQseVNgpC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Machine learning models"
      ],
      "metadata": {
        "id": "pVXdVZ3HK6b5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Ordinal encoding\n",
        "transform_oe = make_column_transformer((OrdinalEncoder(), cat_data), \n",
        "                                       (StandardScaler(), numeric_data), remainder='passthrough',\n",
        "                                       verbose_feature_names_out= False)\n",
        "train_oe = transform_oe.fit_transform(train)\n",
        "train_oe = pd.DataFrame(train_oe, columns=cat_data + numeric_data + ['Confirmed_Conflict'])\n",
        "\n",
        "test_oe = transform_oe.fit_transform(test)\n",
        "test_oe = pd.DataFrame(test_oe, columns=cat_data + numeric_data + ['Confirmed_Conflict'])\n",
        "\n",
        "# One-hot encoding\n",
        "transform_ohe = make_column_transformer((OneHotEncoder(handle_unknown='ignore'), cat_data),\n",
        "                                        (StandardScaler(), numeric_data), remainder='passthrough',\n",
        "                                        verbose_feature_names_out= False)\n",
        "transform_ohe.fit(train)\n",
        "train_ohe = transform_ohe.transform(train)\n",
        "train_ohe = pd.DataFrame(train_ohe, columns=transform_ohe.get_feature_names_out())\n",
        "\n",
        "test_ohe = transform_ohe.transform(test)\n",
        "test_ohe = pd.DataFrame(test_ohe, columns=transform_ohe.get_feature_names_out())\n",
        "\n",
        "# Select appropriate encoded data for ML models - Ordinal or OneHot\n",
        "train_encoded = train_ohe\n",
        "test_encoded = test_ohe"
      ],
      "metadata": {
        "id": "S5yN-gCAEWk3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(test_ohe.columns)"
      ],
      "metadata": {
        "id": "bW_BF2W7sdi3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def dt_optimization(max_depth, min_samples_leaf):\n",
        "    cv_splits = 3\n",
        "    return cross_val_score(\n",
        "               DecisionTreeClassifier(                                                             \n",
        "                   max_depth=int(max(max_depth,1)),\n",
        "                   min_samples_leaf=int(max(min_samples_leaf,1)), \n",
        "                   random_state=seed,   \n",
        "                   class_weight=\"balanced\"),  \n",
        "               X=train_encoded.drop(['Confirmed_Conflict'],axis=1), \n",
        "               y=train_encoded['Confirmed_Conflict'], \n",
        "               cv=cv_splits,\n",
        "               scoring=\"roc_auc\",\n",
        "               n_jobs=-1).mean()\n",
        "\n",
        "\n",
        "parameters = {\"max_depth\": (5, 150),\n",
        "              \"min_samples_leaf\": (2, 10)}\n",
        "\n",
        "\n",
        "BO_dt = BayesianOptimization(dt_optimization, parameters,verbose = 2, random_state=seed)\n",
        "BO_dt.maximize(init_points = 5, n_iter = 25)\n",
        "\n",
        "print(\"Best result: {}; f(x) = {}.\".format(BO_dt.max[\"params\"], BO_dt.max[\"target\"]))"
      ],
      "metadata": {
        "id": "9PHkiEiH9rzw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_history = []\n",
        "for iter in range(0,len(BO_dt.res)):\n",
        "    opt_history.append({'target': BO_dt.res[iter]['target'],\n",
        "               'max_depth': BO_dt.res[iter]['params']['max_depth'],\n",
        "               'min_samples_leaf':  BO_dt.res[iter]['params']['min_samples_leaf']\n",
        "        })\n",
        "\n",
        "opt_history = pd.DataFrame(opt_history)"
      ],
      "metadata": {
        "id": "rndJOGJ8Wi08"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.tri as tri\n",
        "import numpy as np\n",
        "\n",
        "fig,ax2 = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "# define grid.\n",
        "xi = np.linspace(min(parameters['max_depth']), max(parameters['max_depth']),100)\n",
        "yi = np.linspace(min(parameters['min_samples_leaf']), max(parameters['min_samples_leaf']),100)\n",
        "# grid the data.\n",
        "zi = griddata((opt_history['max_depth'], opt_history['min_samples_leaf']), opt_history['target'],\n",
        "              (xi[None,:], yi[:,None]), method='cubic')\n",
        "# contour the gridded data, plotting dots at the randomly spaced data points.\n",
        "CS = plt.contour(xi,yi,zi,15,linewidths=0.5,colors='k')\n",
        "CS = plt.contourf(xi,yi,zi,15,cmap=plt.cm.Greys)\n",
        "plt.colorbar() # draw colorbar\n",
        "\n",
        "plt.scatter(opt_history['max_depth'], opt_history['min_samples_leaf'], marker='o',c='k',s=20)\n",
        "plt.scatter(opt_history['max_depth'][opt_history['target'].idxmax()],\n",
        "           opt_history['min_samples_leaf'][opt_history['target'].idxmax()], marker='o',c='red',s=40)\n",
        "\n",
        "\n",
        "plt.xlim(parameters['max_depth'])\n",
        "plt.ylim(parameters['min_samples_leaf'])\n",
        "plt.title('Objective function')\n",
        "plt.xlabel('Max depth')\n",
        "plt.ylabel('Min samples leaf')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "auGhEW5QAKWd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= DecisionTreeClassifier(\n",
        "                       max_depth=int(BO_dt.max[\"params\"][\"max_depth\"]),\n",
        "                       min_samples_leaf=int(BO_dt.max[\"params\"][\"min_samples_leaf\"]),\n",
        "                       random_state=seed, \n",
        "                       class_weight=\"balanced\")\n",
        "\n",
        "model_dt = model.fit(train_encoded.drop(['Confirmed_Conflict'],axis=1), train_encoded['Confirmed_Conflict'])\n",
        "y_dt_proba = model_dt.predict_proba(test_encoded.drop(['Confirmed_Conflict'],axis=1))"
      ],
      "metadata": {
        "id": "XOHFdMTQhzzq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = []\n",
        "values = np.linspace(0, 1, num=21)\n",
        "for cutoff in values:\n",
        "  predictions_nominal = [0 if x < cutoff  else 1 for x in y_dt_proba[:,1]] #indexing needed for Class 1\n",
        "  f1.append(f1_score(test['Confirmed_Conflict'], predictions_nominal, average=\"macro\"))\n",
        "\n",
        "f1_dt = f1[np.argmax(f1)]\n",
        "thres_dt = values[np.argmax(f1)]\n",
        "print(\"Optimum macro F1 score = {:0.2f}; Threshold = {:0.2f}.\".format(f1_dt, thres_dt))"
      ],
      "metadata": {
        "id": "QkvYZAWliLcX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_dt = [0 if x < 0.5 else 1 for x in y_dt_proba[:,1]]\n",
        "print(classification_report(test['Confirmed_Conflict'], ypred_dt))"
      ],
      "metadata": {
        "id": "n_3TuJICjzym"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score versus threshold\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(values, f1)\n",
        "plt.plot(thres_dt,f1_dt,marker=\"o\", markersize=5)\n",
        "plt.xlabel('Probability threshold')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('Optimum F1 score - Decision tree')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rE8CDuPoj0SZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_prob = y_dt_proba # create a 2 dimensional array with probabilities of 0 and 1\n",
        "\n",
        "skplt.metrics.plot_roc(test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "skplt.metrics.plot_precision_recall(test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "WBf1BvXQj31M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from dtreeviz.trees import * # remember to load the package\n",
        "import dtreeviz\n",
        "\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "\n",
        "m = dtreeviz.model(model_dt, X_train, y_train,\n",
        "                target_name=\"target\",\n",
        "                feature_names=X_train.columns)\n",
        "\n",
        "v = m.view()\n",
        "v\n",
        "# v.save(\"fig.svg\")"
      ],
      "metadata": {
        "id": "a5FXxw7YJrPG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# v.save(\"fig.svg\")\n",
        "index"
      ],
      "metadata": {
        "id": "jH8bhOmSbU7G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# index = y_train[y_train==1]\n",
        "x = X_train.iloc[:550]\n",
        "m.view(x=x)\n"
      ],
      "metadata": {
        "id": "0FPlhX-3cUa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Random Forest"
      ],
      "metadata": {
        "id": "23VceU6ze7_c"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def rfc_optimization(n_estimators, max_depth, min_samples_split):\n",
        "    cv_splits = 3\n",
        "    return cross_val_score(\n",
        "               RandomForestClassifier(\n",
        "                   n_estimators=int(max(n_estimators,0)),                                                               \n",
        "                   max_depth=int(max(max_depth,1)),\n",
        "                   min_samples_split=int(max(min_samples_split,2)), \n",
        "                   n_jobs=-1, \n",
        "                   random_state=seed,   \n",
        "                   class_weight=\"balanced\"),  \n",
        "               X=train_encoded.drop(['Confirmed_Conflict'],axis=1), \n",
        "               y=train_encoded['Confirmed_Conflict'],  \n",
        "               cv=cv_splits,\n",
        "               scoring=\"roc_auc\",\n",
        "               n_jobs=-1).mean()\n",
        "\n",
        "\n",
        "parameters = {\"n_estimators\": (10, 1000),\n",
        "              \"max_depth\": (5, 150),\n",
        "              \"min_samples_split\": (2, 10)}\n",
        "\n",
        "\n",
        "BO_rf = BayesianOptimization(rfc_optimization, parameters, verbose = 2, random_state=seed)\n",
        "BO_rf.maximize(init_points = 5, n_iter = 20)\n",
        "\n",
        "print(\"Best result: {}; f(x) = {}.\".format(BO_rf.max[\"params\"], BO_rf.max[\"target\"]))"
      ],
      "metadata": {
        "id": "HiaDw9_0OCjU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_history = []\n",
        "for iter in range(0,len(BO_rf.res)):\n",
        "    opt_history.append({'target': BO_rf.res[iter]['target'],\n",
        "               'max_depth': BO_rf.res[iter]['params']['max_depth'],\n",
        "               'n_estimators': BO_rf.res[iter]['params']['n_estimators'],\n",
        "               'min_samples_split':  BO_rf.res[iter]['params']['min_samples_split']\n",
        "        })\n",
        "\n",
        "opt_history = pd.DataFrame(opt_history)"
      ],
      "metadata": {
        "id": "dQHbBPmr4hNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.tri as tri\n",
        "import numpy as np\n",
        "\n",
        "fig,ax2 = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "# define grid.\n",
        "xi = np.linspace(min(parameters['max_depth']), max(parameters['max_depth']),100)\n",
        "yi = np.linspace(min(parameters['min_samples_split']), max(parameters['min_samples_split']),100)\n",
        "# grid the data.\n",
        "zi = griddata((opt_history['max_depth'], opt_history['min_samples_split']), opt_history['target'],\n",
        "              (xi[None,:], yi[:,None]), method='cubic')\n",
        "# contour the gridded data, plotting dots at the randomly spaced data points.\n",
        "CS = plt.contour(xi,yi,zi,15,linewidths=0.5,colors='k')\n",
        "CS = plt.contourf(xi,yi,zi,15,cmap=plt.cm.Greys)\n",
        "plt.colorbar() # draw colorbar\n",
        "\n",
        "plt.scatter(opt_history['max_depth'], opt_history['min_samples_split'], marker='o',c='k',s=20)\n",
        "plt.scatter(opt_history['max_depth'][opt_history['target'].idxmax()],\n",
        "           opt_history['min_samples_split'][opt_history['target'].idxmax()], marker='o',c='red',s=30)\n",
        "\n",
        "\n",
        "plt.xlim(parameters['max_depth'])\n",
        "plt.ylim(parameters['min_samples_split'])\n",
        "plt.title('Objective function')\n",
        "plt.xlabel('Max depth')\n",
        "plt.ylabel('Min sample split')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "Jcl_zFJj4h4s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.tri as tri\n",
        "import numpy as np\n",
        "\n",
        "fig,ax2 = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "# define grid.\n",
        "xi = np.linspace(min(parameters['max_depth']), max(parameters['max_depth']),100)\n",
        "yi = np.linspace(min(parameters['n_estimators']), max(parameters['n_estimators']),100)\n",
        "# grid the data.\n",
        "zi = griddata((opt_history['max_depth'], opt_history['n_estimators']), opt_history['target'],\n",
        "              (xi[None,:], yi[:,None]), method='cubic')\n",
        "# contour the gridded data, plotting dots at the randomly spaced data points.\n",
        "CS = plt.contour(xi,yi,zi,15,linewidths=0.5,colors='k')\n",
        "CS = plt.contourf(xi,yi,zi,15,cmap=plt.cm.Greys)\n",
        "plt.colorbar() # draw colorbar\n",
        "\n",
        "plt.scatter(opt_history['max_depth'], opt_history['n_estimators'], marker='o',c='k',s=20)\n",
        "plt.scatter(opt_history['max_depth'][opt_history['target'].idxmax()],\n",
        "           opt_history['n_estimators'][opt_history['target'].idxmax()], marker='o',c='red',s=30)\n",
        "\n",
        "\n",
        "plt.xlim(parameters['max_depth'])\n",
        "plt.ylim(parameters['n_estimators'])\n",
        "plt.title('Objective function')\n",
        "plt.xlabel('Max depth')\n",
        "plt.ylabel('No of estimators')\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "7z7vbl8m4nbW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model= RandomForestClassifier(\n",
        "                       n_estimators=int(BO_rf.max[\"params\"][\"n_estimators\"]),\n",
        "                       max_depth=int(BO_rf.max[\"params\"][\"max_depth\"]),\n",
        "                       min_samples_split=int(BO_rf.max[\"params\"][\"min_samples_split\"]),\n",
        "                       n_jobs=-1, \n",
        "                      random_state=seed,   \n",
        "                      class_weight=\"balanced\")\n",
        "\n",
        "model_rf = model.fit(train_encoded.drop(['Confirmed_Conflict'],axis=1), train_encoded['Confirmed_Conflict'])\n",
        "y_rf_proba = model_rf.predict_proba(test_encoded.drop(['Confirmed_Conflict'],axis=1))"
      ],
      "metadata": {
        "id": "-mR_uCC9YcWO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = []\n",
        "values = np.linspace(0, 1, num=21)\n",
        "for cutoff in values:\n",
        "  predictions_nominal = [0 if x < cutoff  else 1 for x in y_rf_proba[:,1]] #indexing needed for Class 1\n",
        "  f1.append(f1_score(test['Confirmed_Conflict'], predictions_nominal, average=\"macro\"))\n",
        "\n",
        "f1_rf = f1[np.argmax(f1)]\n",
        "thres_rf = values[np.argmax(f1)]\n",
        "print(\"Optimum macro F1 score = {:0.2f}; Threshold = {:0.2f}.\".format(f1_rf, thres_rf))"
      ],
      "metadata": {
        "id": "N754b4B4Zo6r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_rf = [0 if x < thres_rf else 1 for x in y_rf_proba[:,1]]\n",
        "print(classification_report(test['Confirmed_Conflict'], ypred_rf))"
      ],
      "metadata": {
        "id": "jgHbrSoTqEXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score versus threshold\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(values, f1)\n",
        "plt.plot(thres_rf,f1_rf,marker=\"o\", markersize=5)\n",
        "plt.xlabel('Probability threshold')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('Optimum F1 score - Random Forest')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "reLpyzePqJvF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_prob = y_rf_proba # create a 2 dimensional array with probabilities of 0 and 1\n",
        "\n",
        "skplt.metrics.plot_roc(test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "skplt.metrics.plot_precision_recall(test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "wqqFpN3PqMgW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## XGBoost"
      ],
      "metadata": {
        "id": "BjjbG9Khe_YP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def xgb_optimization(eta, gamma, max_depth):\n",
        "            cv_splits = 3\n",
        "            return cross_val_score(\n",
        "                   xgboost.XGBClassifier(\n",
        "                       objective=\"binary:logistic\",\n",
        "                       learning_rate=max(eta, 0),\n",
        "                       gamma=max(gamma, 0),\n",
        "                       max_depth=int(max_depth),                                               \n",
        "                       seed=42,\n",
        "                       nthread=-1,\n",
        "                       scale_pos_weight = len(train_encoded['Confirmed_Conflict'][train_encoded['Confirmed_Conflict'] == 0])/\n",
        "                                          len(train_encoded['Confirmed_Conflict'][train_encoded['Confirmed_Conflict'] == 1])),  \n",
        "                   X=train_encoded.drop(['Confirmed_Conflict'],axis=1), \n",
        "                   y=train_encoded['Confirmed_Conflict'],\n",
        "                   cv=cv_splits,\n",
        "                   scoring=\"roc_auc\",\n",
        "                   n_jobs=-1).mean()\n",
        "\n",
        "parameters = {\"eta\": (0.001, 0.4),\n",
        "              \"gamma\": (0, 20),\n",
        "              \"max_depth\": (1, 1000)}\n",
        "    \n",
        "\n",
        "BO_xg = BayesianOptimization(xgb_optimization, parameters,verbose = 2, random_state= seed)\n",
        "BO_xg.maximize(init_points = 5, n_iter = 20)\n",
        "\n",
        "print(\"Best result: {}; f(x) = {}.\".format(BO_xg.max[\"params\"], BO_xg.max[\"target\"]))"
      ],
      "metadata": {
        "id": "nmcmy6OHX3tT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "opt_history = []\n",
        "for iter in range(0,len(BO_rf.res)):\n",
        "    opt_history.append({'target': BO_xg.res[iter]['target'],\n",
        "               'eta': BO_xg.res[iter]['params']['eta'],\n",
        "               'gamma': BO_xg.res[iter]['params']['gamma'],\n",
        "               'max_depth':  BO_xg.res[iter]['params']['max_depth']\n",
        "        })\n",
        "\n",
        "opt_history = pd.DataFrame(opt_history)"
      ],
      "metadata": {
        "id": "A0Uy6KXs7Koe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.tri as tri\n",
        "import numpy as np\n",
        "\n",
        "fig,ax2 = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "# define grid.\n",
        "xi = np.linspace(min(parameters['eta']), max(parameters['eta']),100)\n",
        "yi = np.linspace(min(parameters['gamma']), max(parameters['gamma']),100)\n",
        "# grid the data.\n",
        "zi = griddata((opt_history['eta'], opt_history['gamma']), opt_history['target'],\n",
        "              (xi[None,:], yi[:,None]), method='cubic')\n",
        "# contour the gridded data, plotting dots at the randomly spaced data points.\n",
        "CS = plt.contour(xi,yi,zi,15,linewidths=0.5,colors='k')\n",
        "CS = plt.contourf(xi,yi,zi,15,cmap=plt.cm.Greys)\n",
        "plt.colorbar() # draw colorbar\n",
        "\n",
        "plt.scatter(opt_history['eta'], opt_history['gamma'], marker='o',c='k',s=20)\n",
        "plt.scatter(opt_history['eta'][opt_history['target'].idxmax()],\n",
        "           opt_history['gamma'][opt_history['target'].idxmax()], marker='o',c='red',s=30)\n",
        "\n",
        "\n",
        "plt.xlim(parameters['eta'])\n",
        "plt.ylim(parameters['gamma'])\n",
        "plt.title('Objective function')\n",
        "plt.xlabel('Eta')\n",
        "plt.ylabel('Gamma')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ewg6iVWT8BVQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from scipy.interpolate import griddata\n",
        "import matplotlib.tri as tri\n",
        "import numpy as np\n",
        "\n",
        "fig,ax2 = plt.subplots(figsize=(6, 5))\n",
        "\n",
        "# define grid.\n",
        "xi = np.linspace(min(parameters['eta']), max(parameters['eta']),100)\n",
        "yi = np.linspace(min(parameters['max_depth']), max(parameters['max_depth']),100)\n",
        "# grid the data.\n",
        "zi = griddata((opt_history['eta'], opt_history['max_depth']), opt_history['target'],\n",
        "              (xi[None,:], yi[:,None]), method='cubic')\n",
        "# contour the gridded data, plotting dots at the randomly spaced data points.\n",
        "CS = plt.contour(xi,yi,zi,15,linewidths=0.5,colors='k')\n",
        "CS = plt.contourf(xi,yi,zi,15,cmap=plt.cm.Greys)\n",
        "plt.colorbar() # draw colorbar\n",
        "\n",
        "plt.scatter(opt_history['eta'], opt_history['max_depth'], marker='o',c='k',s=20)\n",
        "plt.scatter(opt_history['eta'][opt_history['target'].idxmax()],\n",
        "           opt_history['max_depth'][opt_history['target'].idxmax()], marker='o',c='red',s=30)\n",
        "\n",
        "\n",
        "plt.xlim(parameters['eta'])\n",
        "plt.ylim(parameters['max_depth'])\n",
        "plt.title('Objective function')\n",
        "plt.xlabel('Eta')\n",
        "plt.ylabel('Max depth')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "rR_zBL178GNr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = xgboost.XGBClassifier(\n",
        "                       objective=\"binary:logistic\",\n",
        "                       eta=(BO_xg.max[\"params\"][\"eta\"]),\n",
        "                       gamma=(BO_xg.max[\"params\"][\"gamma\"]),\n",
        "                       max_depth=int(BO_xg.max[\"params\"][\"max_depth\"]),                                               \n",
        "                       seed= seed,\n",
        "                       nthread=-1,\n",
        "                       scale_pos_weight = len(train_encoded['Confirmed_Conflict'][train_encoded['Confirmed_Conflict'] == 0])/\n",
        "                                          len(train_encoded['Confirmed_Conflict'][train_encoded['Confirmed_Conflict'] == 1]))\n",
        "\n",
        "model_xg = model.fit(train_encoded.drop(['Confirmed_Conflict'],axis=1), train_encoded['Confirmed_Conflict'])\n",
        "y_xg_proba = model_xg.predict_proba(test_encoded.drop(['Confirmed_Conflict'],axis=1))"
      ],
      "metadata": {
        "id": "wQrQuzPKgA9i"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "f1 = []\n",
        "values = np.linspace(0, 1, num=21)\n",
        "for cutoff in values:\n",
        "  predictions_nominal = [0 if x < cutoff  else 1 for x in y_xg_proba[:,1]] #indexing needed for Class 1\n",
        "  f1.append(f1_score(test['Confirmed_Conflict'], predictions_nominal, average=\"macro\"))\n",
        "\n",
        "f1_xg = f1[np.argmax(f1)]\n",
        "thres_xg = values[np.argmax(f1)]\n",
        "print(\"Optimum macro F1 score = {:0.2f}; Threshold = {:0.2f}.\".format(f1_xg, thres_xg))"
      ],
      "metadata": {
        "id": "B4fi-XoNzIRo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ypred_xg = [0 if x < 0.5 else 1 for x in y_xg_proba[:,1]]\n",
        "print(classification_report(test['Confirmed_Conflict'], ypred_xg))"
      ],
      "metadata": {
        "id": "bK76fX24txkn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# F1 score versus threshold\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(values, f1)\n",
        "plt.plot(thres_xg,f1_xg,marker=\"o\", markersize=5)\n",
        "plt.xlabel('Probability threshold')\n",
        "plt.ylabel('F1 score')\n",
        "plt.title('Optimum F1 score - XGBoost')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "AagihQgCt2ZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_prob = y_xg_proba # create a 2 dimensional array with probabilities of 0 and 1\n",
        "\n",
        "skplt.metrics.plot_roc(test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "skplt.metrics.plot_precision_recall(test['Confirmed_Conflict'], class_prob, cmap='tab20c', plot_micro=False, figsize=(5,4), text_fontsize=10)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "VQTOCuNht7P3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "feature_imp = pd.Series(model_rf.feature_importances_,\n",
        "                        index=train_encoded.drop(['Confirmed_Conflict'],axis=1).columns).sort_values(ascending=False)\n",
        "\n",
        "# Creating a bar plot\n",
        "# fig, ax = plt.subplots(figsize=(6, 15))\n",
        "seaborn.barplot(x=feature_imp, y=feature_imp.index, palette = \"mako\",)\n",
        "# Add labels to your graph\n",
        "plt.xlabel('Feature Importance Score')\n",
        "plt.ylabel('Features')\n",
        "plt.title(\"Visualizing Important Features\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "W-KeUahyd0CW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "shap_values = shap.Explainer(model_dt).shap_values(train_encoded.drop(['Confirmed_Conflict'],axis=1))\n",
        "shap.summary_plot(shap_values[1], train_encoded.drop(['Confirmed_Conflict'],axis=1))\n"
      ],
      "metadata": {
        "id": "gATWXA0KpkrI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}